{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "creative-imaging",
   "metadata": {},
   "source": [
    "# Multivariate - single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "naked-cleveland",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T16:35:28.353616Z",
     "start_time": "2021-12-26T16:35:28.348600Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "immediate-shell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T15:57:21.894945Z",
     "start_time": "2021-12-26T15:57:21.887953Z"
    }
   },
   "outputs": [],
   "source": [
    "# define input sequence. Example of defining multiple input and a dependent time series.\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cosmetic-gnome",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T15:57:22.384656Z",
     "start_time": "2021-12-26T15:57:22.377659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25,  45,  65,  85, 105, 125, 145, 165, 185])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acting-feature",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T15:57:23.007759Z",
     "start_time": "2021-12-26T15:57:22.999767Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "federal-omega",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T15:57:26.574759Z",
     "start_time": "2021-12-26T15:57:26.566767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10,  15,  25],\n",
       "       [ 20,  25,  45],\n",
       "       [ 30,  35,  65],\n",
       "       [ 40,  45,  85],\n",
       "       [ 50,  55, 105],\n",
       "       [ 60,  65, 125],\n",
       "       [ 70,  75, 145],\n",
       "       [ 80,  85, 165],\n",
       "       [ 90,  95, 185]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cheap-facing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T15:58:16.213629Z",
     "start_time": "2021-12-26T15:58:16.205616Z"
    }
   },
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "occupied-samoa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T15:58:49.589105Z",
     "start_time": "2021-12-26T15:58:49.579114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 3, 2) (7,)\n",
      "[[10 15]\n",
      " [20 25]\n",
      " [30 35]] 65\n",
      "[[20 25]\n",
      " [30 35]\n",
      " [40 45]] 85\n",
      "[[30 35]\n",
      " [40 45]\n",
      " [50 55]] 105\n",
      "[[40 45]\n",
      " [50 55]\n",
      " [60 65]] 125\n",
      "[[50 55]\n",
      " [60 65]\n",
      " [70 75]] 145\n",
      "[[60 65]\n",
      " [70 75]\n",
      " [80 85]] 165\n",
      "[[70 75]\n",
      " [80 85]\n",
      " [90 95]] 185\n"
     ]
    }
   ],
   "source": [
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps) # X follows [samples, timesteps, features]\n",
    "print(X.shape, y.shape)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fleet-moment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T16:13:19.400512Z",
     "start_time": "2021-12-26T16:13:19.230613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50)                10600     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,651\n",
      "Trainable params: 10,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "n_features = 2\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "differential-works",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T16:14:09.018792Z",
     "start_time": "2021-12-26T16:14:08.944838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-15.924228]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction, Example of making an out-of-sample forecast\n",
    "x_input = array([[80, 85], [90, 95], [100, 105]])\n",
    "x_input = x_input.reshape((1, n_steps, n_features)) # (1 sample, 3 time steps, 2 features)\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-edinburgh",
   "metadata": {},
   "source": [
    "# Univariate Multi-step LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-tamil",
   "metadata": {},
   "source": [
    "## Vector Output Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "miniature-presentation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T16:22:38.683133Z",
     "start_time": "2021-12-26T16:22:38.669144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30] [40 50]\n",
      "[20 30 40] [50 60]\n",
      "[30 40 50] [60 70]\n",
      "[40 50 60] [70 80]\n",
      "[50 60 70] [80 90]\n"
     ]
    }
   ],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "junior-shade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T16:22:49.270268Z",
     "start_time": "2021-12-26T16:22:49.265273Z"
    }
   },
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "meaningful-cigarette",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T16:22:52.216475Z",
     "start_time": "2021-12-26T16:22:51.986590Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(n_steps_out)) # 这里用于产生2个output，Vector Output，相当于multi-step ahead\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "valuable-square",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T16:23:19.011159Z",
     "start_time": "2021-12-26T16:23:15.532127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[116.064804 138.10678 ]]\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=50, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-madness",
   "metadata": {},
   "source": [
    "## Encoder-Decoder LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-nursery",
   "metadata": {},
   "source": [
    "The model was designed for prediction problems where there are both input and output sequences, so-called sequence-to-sequence, or seq2seq problems, such as translating text from one language to another. This model can be used for multi-step time series forecasting. As its name suggests, the model is comprised of two sub-models: the encoder and the decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-marshall",
   "metadata": {},
   "source": [
    "The encoder is a model responsible for reading and interpreting the input sequence. The output of the encoder is a fixed length vector that represents the model’s interpretation of the sequence. The encoder is traditionally a Vanilla LSTM model, although other encoder models can be used such as Stacked, Bidirectional, and CNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "atmospheric-eagle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T16:36:06.286453Z",
     "start_time": "2021-12-26T16:36:06.158528Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# define encoder model\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_steps_in, n_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-toner",
   "metadata": {},
   "source": [
    "The decoder uses the output of the encoder as an input. First, the **fixed-length output of the encoder is repeated**, once for each required time step in the output sequence.\n",
    "\n",
    "If the number of input and output time steps vary, then an Encoder-Decoder architecture can be used. The input time steps are mapped to a **fixed sized internal representation of the sequence**, then this vector is **used as input** to **producing each time step** in the **output sequence**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "hungry-connection",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T16:36:07.376263Z",
     "start_time": "2021-12-26T16:36:07.361272Z"
    }
   },
   "outputs": [],
   "source": [
    "# repeat encoding\n",
    "model.add(RepeatVector(n_steps_out)) # RepeatVector将输入重复2次，即这里改变我们的步长（从1）变为n_steps_out == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-metallic",
   "metadata": {},
   "source": [
    "This sequence is then provided to an LSTM decoder model. The model must output a value for each value in the output time step, which can be interpreted by a single output model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "south-ballot",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T16:36:08.715759Z",
     "start_time": "2021-12-26T16:36:08.596830Z"
    }
   },
   "outputs": [],
   "source": [
    "# define decoder model\n",
    "# return_sequences=True since we need to output a value for each value \n",
    "# in the output time step\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-thursday",
   "metadata": {},
   "source": [
    "We can use the same output layer or layers to make each one-step prediction in the output sequence. This can be achieved by wrapping the output part of the model in a TimeDistributed wrapper.\n",
    "\n",
    "TimeDistributed层在每个时间步上均操作了Dense，由上面几个图明显可以看出了增加了模型实现一对多和多对多的能力。如果你使用正常的Dense层，你最后只会得到一个结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "opposite-revolution",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T16:36:10.314261Z",
     "start_time": "2021-12-26T16:36:10.285283Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model output\n",
    "# The output layer predicts one observation per output time step \n",
    "# and is wrapped in a TimeDistributed wrapper layer in order to \n",
    "# use the same output layer multiple times for the required number of output time steps.\n",
    "model.add(TimeDistributed(Dense(1)))  # TimeDistributed使每个步长（2）输出一个值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "loved-cowboy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T19:34:17.710531Z",
     "start_time": "2021-12-26T19:34:17.443683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " repeat_vector_4 (RepeatVect  (None, 2, 100)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 2, 100)            80400     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2, 1)              101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# all together\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "# RepeatVector将输入重复2次，即这里改变我们的步长（从1）变为n_steps_out=2。\n",
    "# 这里相当于把第一个LSTM的输出（1个）复制成2个，再接入stack的第二个LSTM。\n",
    "# 第一个LSTM的每个输出相当于是第二个LSTM的每个步长（总共2个步长）\n",
    "model.add(RepeatVector(n_steps_out)) \n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "# 第二个LSTM输出时，依次用这2个步长产生两个预测值，即达到了multi-step ahead的目的\n",
    "model.add(TimeDistributed(Dense(1))) # TimeDistributed使每个步长（2）用相同的input，输出一个值，即这里最后输出两个值\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "urban-guest",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T19:38:26.558085Z",
     "start_time": "2021-12-26T19:38:26.550090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps_in, n_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-kentucky",
   "metadata": {},
   "source": [
    "TimeDistributed和Dense的使用 [https://blog.csdn.net/ChaoFeiLi/article/details/89323078]\n",
    "\n",
    "1、TimeDistributed和Dense的使用\n",
    "\n",
    "下面代码是keras里面给出的解释：\n",
    "\n",
    "  \\# as the first layer in a model\n",
    "  \n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(Dense(8), input_shape=(10, 16)))\n",
    "  \\# now model.output_shape == (None, 10, 8)\n",
    "\n",
    "从上述代码中可以发现，TimeDistributed和Dense一起配合使用，主要应用于一对多，多对多的情况。\n",
    "input_shape = (10,16)，表示步长是10，每一步的维度为16，（即：每一个数据的属性长度为16））\n",
    "\n",
    "首先使用TimeDistributed（Dense（8），input_shape = (10,16)）把每一步的维度为16变成8，不改变步长的大小\n",
    "\n",
    "若该层的批输入形状为(50, 10, 16)，则这一层之后的输出为(50, 10, 8)，即每个sample都用于提供了输出。\n",
    "\n",
    "2、RepeatVector的使用\n",
    "\n",
    "这个是keras官网给出的解释\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, input_dim=32))\n",
    "        # now: model.output_shape == (None, 32)\n",
    "        # note: `None` is the batch dimension\n",
    "\n",
    "        model.add(RepeatVector(3))\n",
    "        # now: model.output_shape == (None, 3, 32)\n",
    "\n",
    "\n",
    "解释：如果输入的形状为（None,32），经过添加RepeatVector(3)层之后，输出变为（None,3,32）,RepeatVector改变了我们的步长，不改变我们的每一步的维数（即：属性长度）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "alike-procedure",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T19:47:58.975189Z",
     "start_time": "2021-12-26T19:47:58.970194Z"
    }
   },
   "outputs": [],
   "source": [
    "# [samples, timesteps, features]\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "capable-filling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T19:48:00.361635Z",
     "start_time": "2021-12-26T19:48:00.354622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-special",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T16:38:14.264421Z",
     "start_time": "2021-12-26T16:38:14.257439Z"
    }
   },
   "source": [
    "In the case of the Encoder-Decoder model, the output, or y part, of the training dataset must also have this shape. This is because the model will predict a given number of time steps with a given number of features for each input sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "possible-liberal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T19:48:11.879851Z",
     "start_time": "2021-12-26T19:48:11.875841Z"
    }
   },
   "outputs": [],
   "source": [
    "# reshape output training data\n",
    "y = y.reshape((y.shape[0], y.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "requested-marketing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T19:48:12.410483Z",
     "start_time": "2021-12-26T19:48:12.404487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "marine-dominant",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T19:48:13.133174Z",
     "start_time": "2021-12-26T19:48:13.125182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[40],\n",
       "        [50]],\n",
       "\n",
       "       [[50],\n",
       "        [60]],\n",
       "\n",
       "       [[60],\n",
       "        [70]],\n",
       "\n",
       "       [[70],\n",
       "        [80]],\n",
       "\n",
       "       [[80],\n",
       "        [90]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ideal-michigan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T19:48:20.762889Z",
     "start_time": "2021-12-26T19:48:17.085082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 99.89218]\n",
      "  [114.39776]]]\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=100, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-scotland",
   "metadata": {},
   "source": [
    "# Multivariate Multi-step LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-creator",
   "metadata": {},
   "source": [
    "## Vector Output Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "connected-russell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T19:56:35.493734Z",
     "start_time": "2021-12-26T19:56:35.485754Z"
    }
   },
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-score",
   "metadata": {},
   "source": [
    "Use three prior time steps of each of the two input time series to predict two time\n",
    "steps of the output time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "arabic-diana",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T19:59:07.263075Z",
     "start_time": "2021-12-26T19:59:07.248072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3, 2) (6, 2)\n",
      "[[10 15]\n",
      " [20 25]\n",
      " [30 35]] [65 85]\n",
      "[[20 25]\n",
      " [30 35]\n",
      " [40 45]] [ 85 105]\n",
      "[[30 35]\n",
      " [40 45]\n",
      " [50 55]] [105 125]\n",
      "[[40 45]\n",
      " [50 55]\n",
      " [60 65]] [125 145]\n",
      "[[50 55]\n",
      " [60 65]\n",
      " [70 75]] [145 165]\n",
      "[[60 65]\n",
      " [70 75]\n",
      " [80 85]] [165 185]\n"
     ]
    }
   ],
   "source": [
    "# define input sequence\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# covert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "print(X.shape, y.shape)\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "n_features = X.shape[2]\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "designing-cinema",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T19:59:12.605742Z",
     "start_time": "2021-12-26T19:59:12.362900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_21 (LSTM)              (None, 3, 100)            41200     \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,802\n",
      "Trainable params: 121,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(n_steps_out)) # output a vector for multi-step ahead\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cognitive-browser",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T19:59:19.053855Z",
     "start_time": "2021-12-26T19:59:14.961155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002AC0A91DD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[186.44644 208.8712 ]]\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([[70, 75], [80, 85], [90, 95]])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-patrol",
   "metadata": {},
   "source": [
    "## Encoder-Decoder LSTM (略，跟univariate一样)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-interaction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-monitor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-council",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-possession",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-ecuador",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-viking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "281.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
